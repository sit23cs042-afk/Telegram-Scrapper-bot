"""
System Diagnostics for URL Scraping Issues
==========================================
Run this to diagnose why URLs are showing "Not found"
"""

import sys
import requests
from urllib.parse import urlparse

print("üîç SYSTEM DIAGNOSTICS")
print("=" * 70)

# Test 1: Check Python version
print("\n1Ô∏è‚É£ Python Version:")
print(f"   {sys.version}")

# Test 2: Check required packages
print("\n2Ô∏è‚É£ Required Packages:")
packages = {
    'requests': None,
    'beautifulsoup4': 'bs4',
    'selenium': None,
    'telethon': None,
    'supabase': None
}

for pkg, import_name in packages.items():
    try:
        if import_name:
            __import__(import_name)
        else:
            __import__(pkg)
        print(f"   ‚úÖ {pkg}")
    except ImportError:
        print(f"   ‚ùå {pkg} - NOT INSTALLED")

# Test 3: Check internet connectivity
print("\n3Ô∏è‚É£ Internet Connectivity:")
test_urls = [
    'https://www.google.com',
    'https://www.amazon.in',
    'https://www.flipkart.com',
    'https://amzn.to'
]

for url in test_urls:
    try:
        response = requests.get(url, timeout=5, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        print(f"   ‚úÖ {urlparse(url).netloc} - {response.status_code}")
    except requests.exceptions.Timeout:
        print(f"   ‚è±Ô∏è {urlparse(url).netloc} - TIMEOUT")
    except requests.exceptions.ConnectionError:
        print(f"   ‚ùå {urlparse(url).netloc} - CONNECTION FAILED")
    except Exception as e:
        print(f"   ‚ö†Ô∏è {urlparse(url).netloc} - {str(e)[:50]}")

# Test 4: Check Selenium/ChromeDriver
print("\n4Ô∏è‚É£ Selenium & ChromeDriver:")
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.chrome.service import Service
    from webdriver_manager.chrome import ChromeDriverManager
    
    print("   ‚úÖ Selenium installed")
    
    try:
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.get('https://www.google.com')
        print(f"   ‚úÖ ChromeDriver working - Version detected")
        driver.quit()
    except Exception as e:
        print(f"   ‚ùå ChromeDriver error: {str(e)[:80]}")
        
except ImportError:
    print("   ‚ùå Selenium not installed")

# Test 5: Check URL Expander
print("\n5Ô∏è‚É£ URL Expander Test:")
from url_expander import URLExpander

expander = URLExpander()
test_short_urls = [
    'https://amzn.to/test',  # Will fail but tests connectivity
    'https://www.amazon.in/dp/B0CX23V2ZK'  # Direct URL
]

for url in test_short_urls:
    try:
        expanded = expander.expand_url(url)
        if expanded and expanded != url:
            print(f"   ‚úÖ {url[:30]}... ‚Üí {expanded[:50]}...")
        elif expanded:
            print(f"   ‚ÑπÔ∏è  {url[:30]}... ‚Üí No redirect (direct URL)")
        else:
            print(f"   ‚ö†Ô∏è {url[:30]}... ‚Üí Failed to expand")
    except Exception as e:
        print(f"   ‚ùå {url[:30]}... ‚Üí Error: {str(e)[:50]}")

# Test 6: Check Firewall/Proxy
print("\n6Ô∏è‚É£ Network Configuration:")
try:
    import os
    http_proxy = os.environ.get('HTTP_PROXY') or os.environ.get('http_proxy')
    https_proxy = os.environ.get('HTTPS_PROXY') or os.environ.get('https_proxy')
    
    if http_proxy or https_proxy:
        print(f"   ‚ö†Ô∏è Proxy detected:")
        if http_proxy:
            print(f"      HTTP: {http_proxy}")
        if https_proxy:
            print(f"      HTTPS: {https_proxy}")
    else:
        print("   ‚úÖ No proxy configured (direct connection)")
except Exception as e:
    print(f"   ‚ö†Ô∏è Error checking proxy: {e}")

# Test 7: Test Product Scraper
print("\n7Ô∏è‚É£ Product Scraper Test:")
try:
    from product_scraper import ProductScraperFactory
    
    scraper = ProductScraperFactory()
    test_url = 'https://www.amazon.in/dp/B0CX23V2ZK'
    
    print(f"   Testing: {test_url}")
    result = scraper.scrape_product(test_url)
    
    if result.get('success'):
        print(f"   ‚úÖ Scraper working")
        print(f"      Title extracted: {'Yes' if result.get('title') else 'No'}")
        print(f"      Price extracted: {'Yes' if result.get('offer_price') else 'No'}")
    else:
        print(f"   ‚ùå Scraper failed: {result.get('error', 'Unknown error')}")
        
except Exception as e:
    print(f"   ‚ùå Scraper error: {str(e)[:80]}")

print("\n" + "=" * 70)
print("\nüìã DIAGNOSIS SUMMARY:")
print("\nIf you see ‚ùå or ‚ö†Ô∏è above, that's likely causing the 'Not found' error.")
print("\nCommon fixes:")
print("  ‚Ä¢ Install missing packages: pip install -r requirements.txt")
print("  ‚Ä¢ Check firewall/antivirus blocking Python/Chrome")
print("  ‚Ä¢ Verify internet connection to Amazon/Flipkart domains")
print("  ‚Ä¢ Try running as Administrator (for ChromeDriver)")
print("  ‚Ä¢ Check if workplace/network blocks e-commerce sites")
print("\n" + "=" * 70)
